# data-tools-utils
A curated list of useful tools and utils for data science and analytics.

# Data processing
1. [Great Expectations](https://greatexpectations.io/) - Data quality assurance
> Great Expectations helps data teams eliminate pipeline debt, through data testing, documentation, and profiling. Empowers data developers to ensure data quality.

2. [dbt](https://github.com/fishtown-analytics/dbt) - Data transformation
> dbt (data build tool) enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications.

3. [dbt-expectations](https://github.com/calogica/dbt-expectations)	- Data transformation + quality check
> Extension package for dbt utilising Great Expectations

# Data labelling	
1. [Snorkel](https://github.com/snorkel-team/snorkel) - Programmatically build and manage training data for ML models
> For ML developers who want to reduce data labelling time.

# Data applications
1. [Streamlit](https://www.streamlit.io/) - Interactive data demos
> Rapid development of performant data apps in Python.
2. [Gradio](https://www.gradio.app/)
> Similar to streamlit - trades control for simplicity

# ML engineering
1. [Hummingbird](https://github.com/microsoft/hummingbird) - Blazing fast production grade models
> Compile traditional ML trained models to tensor operations for GPU-accelerated inference
2. [Horovod](https://github.com/horovod/horovod) - Distributed deep learning training framework
3. [Replicate](https://replicate.ai/), [Sacred](https://github.com/IDSIA/sacred), [other comparisons](https://neptune.ai/blog/best-ml-experiment-tracking-tools) - Version control for ML
> Track experiments and revert models
4. [Talos](https://autonomio.github.io/talos/) - Hyperparameter optimisation for deep learning
> Automate hyperparameter tuning without changing your workflow

# ML analysis
1. [What-if tool](https://pair-code.github.io/what-if-tool/) - ML probing + data understanding with [facets](https://pair-code.github.io/facets/)
> Visualise model performance and fairness, and simulate prediction differences with feature perturbations